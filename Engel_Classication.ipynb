{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "#### Python notebook for Engel outcome prediction (same workflow for Naming outcome)\n",
    "#### Scikit-Learn library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold, RepeatedStratifiedKFold, train_test_split,cross_val_predict\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from numpy import savetxt, loadtxt\n",
    "\n",
    "from sklearn.inspection import partial_dependence\n",
    "from sklearn.inspection import plot_partial_dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Data and prepocessing**\n",
    "\n",
    "First, let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from csv\n",
    "input_file = \"./Data_Neuropsy.csv\"\n",
    "# semi-comma delimited is the default\n",
    "data_raw = pd.read_csv(input_file, header = 0, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drop samples with missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complet = data_raw.iloc[:,1:54].dropna()\n",
    "X = data_complet.iloc[:,0:51]\n",
    "# target variable\n",
    "y = np.ravel(data_complet[[\"ENG_bin\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Standard scaling for continuous variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[['AGE','EDH','AHS','ASO','DUR','FRQ','AED','SEV','EDU']]=scaler.fit_transform(X[['AGE','EDH','AHS','ASO','DUR','FRQ','AED','SEV','EDU']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.iloc[:,16:51]=scaler.fit_transform(X.iloc[:,16:51])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sub dataset selection :  PRI, VMI, VCI, AMI, NAM, SFL, PFL, TMT, STR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = X[[\"PRI\", \"VMI\", \"VCI\", \"AMI\", \"NAM\", \"SFL\", \"PFL\", \"TMT\", \"STR\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Evaluation Using Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# model\n",
    "\n",
    "model = LogisticRegression(penalty=\"l2\", solver='liblinear', class_weight='balanced')\n",
    "\n",
    "# evaluate the model using 10-fold cross-validation repeated 100 times and balanced accuracy\n",
    "\n",
    "n_splits = 10\n",
    "n_repeats = 100\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range (n_repeats):\n",
    "    cv=StratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "    scores_temp=[]\n",
    "    scores_temp=cross_val_score(model, X, y, scoring='balanced_accuracy',cv=cv)\n",
    "    scores.append(scores_temp.mean())      \n",
    "\n",
    "scores = np.asarray(scores)\n",
    "\n",
    "print (f'Overall Balanced Accuracy mean :{scores.mean():.2f}')\n",
    "print (f'Overall Balanced Accuracy std :{scores.std():.2f}')\n",
    "\n",
    "# evaluate the model using k-fold cross-validation repeated 1000 times and roc AUC\n",
    "\n",
    "scores=[]\n",
    "\n",
    "for i in range (n_repeats):\n",
    "    cv=StratifiedKFold(n_splits=n_splits, random_state=i, shuffle=True)\n",
    "    scores_temp=[]\n",
    "    scores_temp=cross_val_score(model, X, y, scoring='roc_auc',cv=cv)\n",
    "    scores.append(scores_temp.mean())      \n",
    "\n",
    "scores = np.asarray(scores) \n",
    "\n",
    "\n",
    "print (f'Overall AUC mean :{scores.mean():.2f}')\n",
    "print (f'Overall AUC std :{scores.std():.2f}')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc3d8109-ebc5-264c-f964-04f66da0fec0",
    "_uuid": "a3668fbd5d02ee623aaf7f2cbc430c8301989db3"
   },
   "source": [
    "## **Feature Selection workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Algorithm choice\n",
    "logisticL1 = LogisticRegression(penalty=\"l1\", solver='liblinear', class_weight='balanced', n_jobs = -1)\n",
    "logisticL2 = LogisticRegression(penalty=\"l2\", solver='liblinear', class_weight='balanced', n_jobs = -1)\n",
    "Tree = ExtraTreesClassifier(n_estimators=50, n_jobs = -1)\n",
    "\n",
    "performance=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "matrix = []\n",
    "\n",
    "iterations = 100\n",
    "features=[]\n",
    "\n",
    "\n",
    "for i in range (1,iterations+1):\n",
    "    # Cross-validation scheme\n",
    "    cv=StratifiedKFold(n_splits=5, random_state=i, shuffle=True)\n",
    "    \n",
    "    for train_index, test_index in cv.split(X,y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]  \n",
    "\n",
    "        # Feature selection by L2-logisitic regression on training set\n",
    "        embeded_lr_selector = SelectFromModel(logisticL2)\n",
    "        embeded_lr_selector.fit(X_train, y_train)\n",
    "        embeded_lr_support = embeded_lr_selector.get_support(indices=False)\n",
    "        \n",
    "        # Record selected features for stability measure\n",
    "        features.append(embeded_lr_support)\n",
    "\n",
    "        # Select only important features for the performance measure\n",
    "        X_test = embeded_lr_selector.transform(X_test)\n",
    "        X_train = embeded_lr_selector.transform(X_train)\n",
    "\n",
    "        # Model fitting\n",
    "        logisticL2.fit(X_train, y_train)\n",
    "        y_pred = logisticL2.predict(X_test)\n",
    "    \n",
    "        # Record performance for iteration i\n",
    "        performance.append(balanced_accuracy_score(y_test,y_pred))\n",
    "        precision.append(precision_score(y_test,y_pred))\n",
    "        recall.append(recall_score(y_test,y_pred))\n",
    "        \n",
    "        matrix.append(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "performance = np.asarray(performance)\n",
    "precision = np.array(precision)\n",
    "recall = np.array(recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save selected feaures to calculate Phi\n",
    "# http://www.cs.man.ac.uk/~gbrown/stability/\n",
    "df = 1*pd.DataFrame(features,  columns=None)\n",
    "df.to_csv(\"features_stability.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stability as st\n",
    "# help(st)\n",
    "stab=st.getStability(np.array(df))\n",
    "print('Stability of ENG_bin is :',stab)\n",
    "varstab = st.getVarianceofStability(np.array(df))\n",
    "print('Variance of the random procedure with M=10 is:',varstab['variance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "print ('BAcc Mean', performance.mean())\n",
    "print ('BAcc Std', performance.std())\n",
    "print ('BAcc Median', np.median(performance))\n",
    "\n",
    "print ('Precision Mean', precision.mean())\n",
    "print ('Precision Std', precision.std())\n",
    "print ('Precision Median', np.median(precision))\n",
    "\n",
    "print ('Recall Mean', recall.mean())\n",
    "print ('Recall Std', recall.std())\n",
    "print ('Recall Median', np.median(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = np.mean(matrix, axis=0)\n",
    "ENG1 = CM[0,0]+CM[0,1]\n",
    "ENG2 = CM[1,0]+CM[1,1]\n",
    "CM[0,0] = CM[0,0]/ENG1*100\n",
    "CM[0,1] = CM[0,1]/ENG1*100\n",
    "CM[1,0] = CM[1,0]/ENG2*100\n",
    "CM[1,1] = CM[1,1]/ENG2*100\n",
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution display\n",
    "histo = performance\n",
    "histo = np.round(histo,3)\n",
    "histo = [\"%.1f\" % x for x in histo]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,15)) \n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale=2)\n",
    "\n",
    "\n",
    "data = pd.DataFrame(histo, columns=['Performance'])\n",
    "data = data.groupby(\"Performance\").size()   # data underlying bar plot in question\n",
    "\n",
    "pal = sns.color_palette(\"YlGn_r\", len(data)) # Balanced Accuracy\n",
    "rank = data.argsort().argsort()   # http://stackoverflow.com/a/6266510/1628638\n",
    "b = sns.barplot(x=data.index, y=data, palette=np.array(pal[::-1])[rank])\n",
    "\n",
    "b.axes.set_title(\"Feature Selection Workflow - Model balanced accuracy performance\",fontsize=20)\n",
    "b.set_xlabel(\"Balanced Accuracy of each 5-CV fold\",fontsize=30)\n",
    "b.set_ylabel(\"Iterations\",fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.empty(shape=(9,2),dtype='object')\n",
    "for i in range(9):\n",
    "    out[i,0] = i\n",
    "    out[i,1] = int(df[[i]].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dataframe = pd.DataFrame(performance,  columns=None)\n",
    "freq = pd.DataFrame(out,  columns=['Index','Frequency'])\n",
    "freq['Scores']=columns\n",
    "freq = freq.sort_values('Frequency', ascending=False)\n",
    "# Let's plot the ranking of the features\n",
    "sns.set(rc={'figure.figsize':(25,12)})\n",
    "sns.set(style=\"whitegrid\")\n",
    "sns.barplot(y = freq.iloc[:,2], x= freq.iloc[:,1], palette='coolwarm_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc3d8109-ebc5-264c-f964-04f66da0fec0",
    "_uuid": "a3668fbd5d02ee623aaf7f2cbc430c8301989db3"
   },
   "source": [
    "# **Performance on Selected Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = X_dataset[[\"VMI\",\"NAM\",\"TMT\",\"AMI\"]],y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "model = LogisticRegression(penalty=\"none\", class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "# evaluate the model using k-fold cross-validation repeated 100 times and balanced accuracy\n",
    "\n",
    "scores=[]\n",
    "\n",
    "matrix=[]\n",
    "\n",
    "for i in range (1,100):\n",
    "    cv=StratifiedKFold(n_splits=5, random_state=i, shuffle=True)\n",
    "    \n",
    "    y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "    matrix.append(confusion_matrix(y, y_pred))\n",
    "\n",
    "# evaluate the model using k-fold cross-validation repeated 1000 times and roc AUC\n",
    "  \n",
    "scores=[]\n",
    "for i in range (1,100):\n",
    "    cv=StratifiedKFold(n_splits=5, random_state=i, shuffle=True)\n",
    "    scores_temp=[]\n",
    "    scores_temp=cross_val_score(model, X, y, scoring='balanced_accuracy',cv=cv)\n",
    "    scores.append(scores_temp.mean())      \n",
    "\n",
    "scores = np.asarray(scores)\n",
    "\n",
    "print (f'Overall BACC mean :{scores.mean():.3f}')\n",
    "print (f'Overall BACC std :{scores.std():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = np.mean(matrix, axis=0)\n",
    "ENG1 = CM[0,0]+CM[0,1]\n",
    "ENG2 = CM[1,0]+CM[1,1]\n",
    "CM[0,0] = CM[0,0]/ENG1*100\n",
    "CM[0,1] = CM[0,1]/ENG1*100\n",
    "CM[1,0] = CM[1,0]/ENG2*100\n",
    "CM[1,1] = CM[1,1]/ENG2*100\n",
    "CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fc3d8109-ebc5-264c-f964-04f66da0fec0",
    "_uuid": "a3668fbd5d02ee623aaf7f2cbc430c8301989db3"
   },
   "source": [
    "# **Partial Dependence Plots on complete Dataset with 5-CV subsampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty=\"l2\", solver='liblinear', class_weight='balanced', n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (25,25)\n",
    "\n",
    "print('Computing partial dependence plots...')\n",
    "\n",
    "features = [\"AMI\",\"VMI\",\"TMT\",\"NAM\",('AMI','VMI'),('AMI','TMT'),('AMI','NAM'),('VMI','TMT'),('VMI','NAM'),('TMT','NAM')]\n",
    "plot_partial_dependence(model, X_train, features,n_jobs=-1, grid_resolution=20)\n",
    "fig = plt.gcf()\n",
    "fig.suptitle('Partial dependence plots')\n",
    "fig.subplots_adjust(hspace=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "fig = plt.figure()\n",
    "\n",
    "features = ('VMI', 'AMI')\n",
    "pdp, axes = partial_dependence(model, X_train, features=features,\n",
    "                               grid_resolution=20)\n",
    "XX, YY = np.meshgrid(axes[0], axes[1])\n",
    "Z = pdp[0].T\n",
    "ax = Axes3D(fig)\n",
    "surf = ax.plot_surface(XX, YY, Z, rstride=1, cstride=1,\n",
    "                       cmap=plt.cm.BuPu, edgecolor='k')\n",
    "ax.set_xlabel(features[0])\n",
    "ax.set_ylabel(features[1])\n",
    "ax.set_zlabel('Partial dependence')\n",
    "#  pretty init view\n",
    "ax.view_init(elev=22, azim=122)\n",
    "plt.colorbar(surf)\n",
    "plt.suptitle('Partial dependence')\n",
    "plt.subplots_adjust(top=0.9)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
